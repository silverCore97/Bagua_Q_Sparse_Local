steps:
  - label: "benchmark_master"
    parallelism: 1
    command: bash .buildkite/scripts/benchmark_master.sh
    plugins:
      - docker#v3.8.0:
          image: "baguasys/bagua:master-pytorch-1.9.0-cuda11.1-cudnn8"
          workdir: /upstream
          user: root
          propagate-environment: true
          runtime: nvidia
          network: host
          ipc: host
          shm-size: 100gb
          always-pull: true
    agents:
      queue: "master"
  - label: "benchmark_worker"
    parallelism: 1
    command: bash .buildkite/scripts/benchmark_worker.sh
    plugins:
      - docker#v3.8.0:
          image: "baguasys/bagua:master-pytorch-1.9.0-cuda11.1-cudnn8"
          workdir: /upstream
          user: root
          propagate-environment: true
          runtime: nvidia
          network: host
          ipc: host
          shm-size: 100gb
          always-pull: true
  - label: "autotune_test"
    parallelism: 1
    command: bash .buildkite/scripts/benchmark.sh
    plugins:
      - docker#v3.8.0:
          image: "baguasys/bagua:master-pytorch-1.9.0-cuda11.1-cudnn8"
          workdir: /upstream
          user: root
          propagate-environment: true
          runtime: nvidia
          network: host
          ipc: host
          shm-size: 100gb
          always-pull: true
  - label: "pytest"
    parallelism: 1
    command: bash .buildkite/scripts/run_pytest.sh
    plugins:
      - docker#v3.8.0:
          image: "baguasys/bagua:master-pytorch-1.9.0-cuda11.1-cudnn8"
          workdir: /upstream
          user: root
          propagate-environment: true
          runtime: nvidia
          network: host
          ipc: host
          shm-size: 100gb
          always-pull: true
